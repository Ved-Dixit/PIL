{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate\n!pip install datasets\n!pip install transformers\n!pip install reportlab\n!pip install datetime\n!pip install flask\n!pip install flask-cors\n!pip install transformers[torch]","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting datasets>=2.0.0 (from evaluate)\n  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\nCollecting numpy>=1.17 (from evaluate)\n  Downloading numpy-2.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nCollecting dill (from evaluate)\n  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\nCollecting pandas (from evaluate)\n  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\nRequirement already satisfied: requests>=2.19.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from evaluate) (2.32.3)\nCollecting tqdm>=4.62.1 (from evaluate)\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nCollecting xxhash (from evaluate)\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting multiprocess (from evaluate)\n  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nCollecting huggingface-hub>=0.7.0 (from evaluate)\n  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.10/site-packages (from evaluate) (24.2)\nCollecting filelock (from datasets>=2.0.0->evaluate)\n  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nCollecting dill (from evaluate)\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\nCollecting multiprocess (from evaluate)\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nCollecting aiohttp (from datasets>=2.0.0->evaluate)\n  Downloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nRequirement already satisfied: pyyaml>=5.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas->evaluate) (2025.1)\nCollecting tzdata>=2022.7 (from pandas->evaluate)\n  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\nCollecting async-timeout<6.0,>=4.0 (from aiohttp->datasets>=2.0.0->evaluate)\n  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: attrs>=17.3.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\nCollecting propcache>=0.2.0 (from aiohttp->datasets>=2.0.0->evaluate)\n  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.0.0->evaluate)\n  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\nDownloading datasets-3.4.0-py3-none-any.whl (487 kB)\nDownloading dill-0.3.8-py3-none-any.whl (116 kB)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\nDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\nDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\nDownloading numpy-2.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\nDownloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\nDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\nDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\nDownloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\nDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\nDownloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\nDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\nInstalling collected packages: xxhash, tzdata, tqdm, pyarrow, propcache, numpy, multidict, fsspec, frozenlist, filelock, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\nSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.13 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.4.0 dill-0.3.8 evaluate-0.4.3 filelock-3.18.0 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.29.3 multidict-6.1.0 multiprocess-0.70.16 numpy-2.2.4 pandas-2.2.3 propcache-0.3.0 pyarrow-19.0.1 tqdm-4.67.1 tzdata-2025.1 xxhash-3.5.0 yarl-1.18.3\nRequirement already satisfied: datasets in /srv/conda/envs/notebook/lib/python3.10/site-packages (3.4.0)\nRequirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (2.2.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (3.11.13)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (0.29.3)\nRequirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.0)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nCollecting transformers\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\nRequirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers) (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers) (2.2.4)\nRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers) (6.0.2)\nCollecting regex!=2019.12.17 (from transformers)\n  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\nRequirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers) (2.32.3)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting safetensors>=0.4.1 (from transformers)\n  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: tqdm>=4.27 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\nDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\nDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nInstalling collected packages: safetensors, regex, tokenizers, transformers\nSuccessfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.49.0\nCollecting reportlab\n  Downloading reportlab-4.3.1-py3-none-any.whl.metadata (1.7 kB)\nCollecting pillow>=9.0.0 (from reportlab)\n  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nCollecting chardet (from reportlab)\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nDownloading reportlab-4.3.1-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\nInstalling collected packages: pillow, chardet, reportlab\nSuccessfully installed chardet-5.2.0 pillow-11.1.0 reportlab-4.3.1\nCollecting datetime\n  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\nCollecting zope.interface (from datetime)\n  Downloading zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\nRequirement already satisfied: pytz in /srv/conda/envs/notebook/lib/python3.10/site-packages (from datetime) (2025.1)\nRequirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.10/site-packages (from zope.interface->datetime) (75.8.0)\nDownloading DateTime-5.5-py3-none-any.whl (52 kB)\nDownloading zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\nInstalling collected packages: zope.interface, datetime\nSuccessfully installed datetime-5.5 zope.interface-7.2\nCollecting flask\n  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting Werkzeug>=3.1 (from flask)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: Jinja2>=3.1.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask) (3.1.5)\nCollecting itsdangerous>=2.2 (from flask)\n  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting click>=8.1.3 (from flask)\n  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: blinker>=1.9 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask) (1.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\nDownloading flask-3.1.0-py3-none-any.whl (102 kB)\nDownloading click-8.1.8-py3-none-any.whl (98 kB)\nDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nInstalling collected packages: Werkzeug, itsdangerous, click, flask\nSuccessfully installed Werkzeug-3.1.3 click-8.1.8 flask-3.1.0 itsdangerous-2.2.0\nCollecting flask-cors\n  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\nRequirement already satisfied: flask>=0.9 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask-cors) (3.1.0)\nRequirement already satisfied: Werkzeug>=0.7 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask-cors) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask>=0.9->flask-cors) (3.1.5)\nRequirement already satisfied: itsdangerous>=2.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask>=0.9->flask-cors) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask>=0.9->flask-cors) (8.1.8)\nRequirement already satisfied: blinker>=1.9 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from flask>=0.9->flask-cors) (1.9.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from Werkzeug>=0.7->flask-cors) (3.0.2)\nDownloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\nInstalling collected packages: flask-cors\nSuccessfully installed flask-cors-5.0.1\nRequirement already satisfied: transformers[torch] in /srv/conda/envs/notebook/lib/python3.10/site-packages (4.49.0)\nRequirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (2.2.4)\nRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\nRequirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\nCollecting torch>=2.0 (from transformers[torch])\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting accelerate>=0.26.0 (from transformers[torch])\n  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: psutil in /srv/conda/envs/notebook/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.8)\nRequirement already satisfied: fsspec>=2023.5.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\nCollecting networkx (from torch>=2.0->transformers[torch])\n  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.1.5)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch>=2.0->transformers[torch])\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting sympy==1.13.1 (from torch>=2.0->transformers[torch])\n  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2.0->transformers[torch])\n  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers[torch]) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\nDownloading accelerate-1.5.2-py3-none-any.whl (345 kB)\nDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\nDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\nDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\nDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, accelerate\nSuccessfully installed accelerate-1.5.2 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.4.0)\nRequirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.5)\nRequirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.29.3)\nRequirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.49.0)\nRequirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: reportlab in /opt/anaconda3/lib/python3.12/site-packages (4.3.1)\nRequirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from reportlab) (10.4.0)\nRequirement already satisfied: chardet in /opt/anaconda3/lib/python3.12/site-packages (from reportlab) (4.0.0)\nRequirement already satisfied: datetime in /opt/anaconda3/lib/python3.12/site-packages (5.5)\nRequirement already satisfied: zope.interface in /opt/anaconda3/lib/python3.12/site-packages (from datetime) (5.4.0)\nRequirement already satisfied: pytz in /opt/anaconda3/lib/python3.12/site-packages (from datetime) (2024.1)\nRequirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from zope.interface->datetime) (75.1.0)\nRequirement already satisfied: flask in /opt/anaconda3/lib/python3.12/site-packages (3.0.3)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (3.0.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (1.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\nRequirement already satisfied: flask-cors in /opt/anaconda3/lib/python3.12/site-packages (5.0.1)\nRequirement already satisfied: flask>=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from flask-cors) (3.0.3)\nRequirement already satisfied: Werkzeug>=0.7 in /opt/anaconda3/lib/python3.12/site-packages (from flask-cors) (3.0.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask>=0.9->flask-cors) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask>=0.9->flask-cors) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from flask>=0.9->flask-cors) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask>=0.9->flask-cors) (1.6.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from Werkzeug>=0.7->flask-cors) (2.1.3)\n"}],"execution_count":1},{"cell_type":"code","source":"# Import libraries\nimport json\nimport os\nfrom datasets import load_dataset\nfrom evaluate import load as load_metric\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    Trainer,\n    TrainingArguments,\n    pipeline,\n)\nfrom datetime import datetime\nfrom reportlab.lib.pagesizes import A4\nfrom reportlab.pdfgen import canvas","metadata":{"trusted":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import requests\nimport zipfile\nimport os\n\n# ✅ Use the direct link to the ZIP file from GitHub Assets\nurl = \"https://github.com/Ved-Dixit/PIL/releases/download/ml/gpt2_pil_trained.zip\"\n\n# Download the ZIP file\nresponse = requests.get(url)\nzip_path = \"gpt2_pil_trained.zip\"\n\n# Save the file\nwith open(zip_path, \"wb\") as f:\n    f.write(response.content)\n\n# Extract the ZIP file\nwith zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n    zip_ref.extractall(\"./model\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ---------------------------\n# ✅ Step 1: Load & Clean Dataset\n# ---------------------------\n\nprint(\"📘 Loading cleaned dataset...\")\n\n# Load the dataset in JSONL format\ndataset = load_dataset(\"json\", data_files=\"data/legal_pil_dataset_fixed.jsonl\")\n","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"📘 Loading cleaned dataset...\n"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9047942695344c31ad22d48e15bacc46","version_major":2,"version_minor":0},"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]"},"metadata":{},"output_type":"display_data"}],"execution_count":3},{"cell_type":"code","source":"\n# ---------------------------\n# 🔧 Step 2: Load GPT-2 Model & Tokenizer\n# ---------------------------\n\nmodel_name = \"gpt2\"\nprint(\"🚀 Loading GPT-2 model...\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# ✅ Fix padding issue\ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"🚀 Loading GPT-2 model...\n"}],"execution_count":4},{"cell_type":"code","source":"# ---------------------------\n# 🔥 Step 3: Tokenize & Setup Training Data\n# ---------------------------\n\ndef tokenize_function(examples):\n    \"\"\"Tokenize and set input labels for GPT-2 to compute loss.\"\"\"\n    tokenized_output = tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=1024,\n    )\n    # ✅ Set labels for loss calculation\n    tokenized_output[\"labels\"] = tokenized_output[\"input_ids\"].copy()\n    return tokenized_output\n\nprint(\"✂️ Tokenizing dataset...\")\ntokenized_dataset = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"✂️ Tokenizing dataset...\n"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"512c920566654ff085ab27bbc3da4362","version_major":2,"version_minor":0},"text/plain":"Map:   0%|          | 0/1477 [00:00<?, ? examples/s]"},"metadata":{},"output_type":"display_data"}],"execution_count":5},{"cell_type":"code","source":"\n","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"# ---------------------------\n# 🔥 Step 5: Train GPT-2\n# ---------------------------\n\nprint(\"🔥 Starting GPT-2 fine-tuning...\")\ntraining_args = TrainingArguments(\n    output_dir=\"./gpt2_pil_trained\",\n    evaluation_strategy=\"steps\",\n    num_train_epochs=2,  # Reduce if needed\n    per_device_train_batch_size=1,  # Reduce from 2 to 1\n    save_total_limit=4,  # Reduce saved checkpoints\n    save_steps=1000,  # Reduce frequency of saving\n    logging_dir=\"./logs\",\n    logging_steps=500,\n    fp16=True  # Enable mixed precision (only for GPUs)\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"train\"],\n)\n\ntrainer.train()\n\n# ✅ Save the fine-tuned model\nmodel.save_pretrained(\"./gpt2_pil_trained\")\ntokenizer.save_pretrained(\"./gpt2_pil_trained\")\n\nprint(\"✅ Fine-tuning complete — model saved!\")\n\"\"\"\n","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"🔥 Starting GPT-2 fine-tuning...\n"},{"name":"stderr","output_type":"stream","text":"  0%|          | 3/2954 [05:34<91:29:29, 111.61s/it]\n 17%|█▋        | 500/2954 [1:05:24<5:18:16,  7.78s/it]\n 17%|█▋        | 500/2954 [1:05:24<5:18:16,  7.78s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.3172, 'grad_norm': 0.7413356304168701, 'learning_rate': 4.1536899119837506e-05, 'epoch': 0.34}\n"},{"name":"stderr","output_type":"stream","text":"\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A                                           \n                                                      \n 17%|█▋        | 500/2954 [1:46:03<5:18:16,  7.78s/it]\n\u001b[A"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.27264729142189026, 'eval_runtime': 2439.4708, 'eval_samples_per_second': 0.605, 'eval_steps_per_second': 0.076, 'epoch': 0.34}\n"},{"name":"stderr","output_type":"stream","text":" 34%|███▍      | 1000/2954 [2:51:46<4:09:51,  7.67s/it]  \n 34%|███▍      | 1000/2954 [2:51:46<4:09:51,  7.67s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.289, 'grad_norm': 0.5477713942527771, 'learning_rate': 3.3073798239675016e-05, 'epoch': 0.68}\n"},{"name":"stderr","output_type":"stream","text":"\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A                                           \n                                                       \n 34%|███▍      | 1000/2954 [3:32:10<4:09:51,  7.67s/it]\n\u001b[A"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.2496897429227829, 'eval_runtime': 2424.5825, 'eval_samples_per_second': 0.609, 'eval_steps_per_second': 0.076, 'epoch': 0.68}\n"},{"name":"stderr","output_type":"stream","text":" 51%|█████     | 1500/2954 [4:36:42<3:10:00,  7.84s/it]   \n 51%|█████     | 1500/2954 [4:36:42<3:10:00,  7.84s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2932, 'grad_norm': 0.6375637054443359, 'learning_rate': 2.4610697359512526e-05, 'epoch': 1.02}\n"},{"name":"stderr","output_type":"stream","text":"\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A                                           \n                                                       \n 51%|█████     | 1500/2954 [5:16:42<3:10:00,  7.84s/it]\n\u001b[A"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.2321518212556839, 'eval_runtime': 2399.9982, 'eval_samples_per_second': 0.615, 'eval_steps_per_second': 0.077, 'epoch': 1.02}\n"},{"name":"stderr","output_type":"stream","text":" 68%|██████▊   | 2000/2954 [6:21:31<2:04:04,  7.80s/it]   \n 68%|██████▊   | 2000/2954 [6:21:31<2:04:04,  7.80s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2305, 'grad_norm': 0.7528636455535889, 'learning_rate': 1.6147596479350036e-05, 'epoch': 1.35}\n"},{"name":"stderr","output_type":"stream","text":"\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A                                           \n                                                       \n 68%|██████▊   | 2000/2954 [7:01:04<2:04:04,  7.80s/it]\n\u001b[A"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.22218036651611328, 'eval_runtime': 2373.3754, 'eval_samples_per_second': 0.622, 'eval_steps_per_second': 0.078, 'epoch': 1.35}\n"},{"name":"stderr","output_type":"stream","text":" 85%|████████▍ | 2500/2954 [8:04:36<57:58,  7.66s/it]     \n 85%|████████▍ | 2500/2954 [8:04:36<57:58,  7.66s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2428, 'grad_norm': 2.480236768722534, 'learning_rate': 7.684495599187543e-06, 'epoch': 1.69}\n"},{"name":"stderr","output_type":"stream","text":"\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A                                           \n                                                     \n 85%|████████▍ | 2500/2954 [8:45:20<57:58,  7.66s/it]\n\u001b[A"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.21552439033985138, 'eval_runtime': 2444.5586, 'eval_samples_per_second': 0.604, 'eval_steps_per_second': 0.076, 'epoch': 1.69}\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 2954/2954 [9:51:18<00:00,  9.42s/it]    \n100%|██████████| 2954/2954 [9:51:20<00:00, 12.01s/it]\n"},{"name":"stdout","output_type":"stream","text":"{'train_runtime': 35480.1174, 'train_samples_per_second': 0.083, 'train_steps_per_second': 0.083, 'train_loss': 0.2722556695957481, 'epoch': 2.0}\n✅ Fine-tuning complete — model saved!\n"}],"execution_count":null},{"cell_type":"code","source":"\n\ngpt2_pil_generator = pipeline(\"text-generation\", model=\"./gpt2_pil_trained\")\n","metadata":{"trusted":false},"outputs":[{"name":"stderr","output_type":"stream","text":"Device set to use mps:0\n"}],"execution_count":8},{"cell_type":"code","source":"\ndef generate_full_pil(subject, petitioner, respondent):\n    \"\"\"Generate the entire PIL document from scratch using GPT-2.\"\"\"\n    prompt = build_smart_prompt(subject)\n\n    result = gpt2_pil_generator(\n        prompt,\n        max_length=1024,\n        temperature=0.4,\n        num_return_sequences=1,\n        truncation=True,\n    )\n\n    return result[0][\"generated_text\"].strip()\n","metadata":{"trusted":false},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\n\n\ndef export_pil(pil_text, filename=\"Generated_PIL_Document\"):\n    \"\"\"Export the PIL to text and PDF files.\"\"\"\n    # Save as TXT\n    with open(f\"{filename}.txt\", \"w\", encoding=\"utf-8\") as file:\n        file.write(pil_text)\n    print(f\"✅ PIL saved as {filename}.txt\")\n\n    # Save as PDF\n    pdf_file = f\"{filename}.pdf\"\n    c = canvas.Canvas(pdf_file, pagesize=A4)\n    c.setFont(\"Helvetica\", 12)\n    for i, line in enumerate(pil_text.split(\"\\n\")):\n        c.drawString(40, 800 - (i * 20), line)\n    c.save()\n    print(f\"✅ PIL saved as {pdf_file}\")\n","metadata":{"trusted":false},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import json\nfrom datetime import datetime\nfrom transformers import pipeline\nfrom reportlab.lib.pagesizes import A4\nfrom reportlab.pdfgen import canvas\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\n# 🚀 Load GPT-2 model\nprint(\"🚀 Loading GPT-2 model...\")\ngpt2_pil_generator = pipeline(\"text-generation\", model=./model)\n\n\n# 🎯 Improved GPT-2 generation with retries and stronger prompts\ndef generate_gpt_section(prompt, section_name=\"\"):\n    \"\"\"Generate sections using GPT-2 with retries and better prompt control.\"\"\"\n    try:\n        # First attempt at generation\n        result = gpt2_pil_generator(\n            prompt,\n            max_length=512,\n            temperature=0.7,\n            top_p=0.9,\n            repetition_penalty=1.2,\n            num_return_sequences=1,\n            do_sample=True,\n            truncation=True,\n        )\n        generated_text = result[0][\"generated_text\"].replace(prompt, \"\").strip()\n\n        # Retry with a stronger prompt if generation fails or gives junk\n        if not generated_text or len(generated_text) < 20:\n            print(f\"⚠️ {section_name} generation failed — retrying with stronger prompt...\")\n            refined_prompt = (\n                f\"{prompt}\\n\\nEnsure the output is legally accurate, clear, and enforceable.\"\n            )\n            refined_result = gpt2_pil_generator(\n                refined_prompt,\n                max_length=512,\n                temperature=0.7,\n                top_p=0.9,\n                repetition_penalty=1.2,\n                num_return_sequences=1,\n                do_sample=True,\n                truncation=True,\n            )\n            generated_text = refined_result[0][\"generated_text\"].replace(refined_prompt, \"\").strip()\n\n        # Final fallback if both attempts fail\n        if not generated_text or len(generated_text) < 20:\n            return f\"⚠️ Unable to generate {section_name}. Please consult a legal expert.\"\n\n        return generated_text\n\n    except Exception as e:\n        print(f\"❌ Error generating {section_name}: {e}\")\n        return f\"⚠️ Error generating {section_name}. Please check the input.\"\n\n\n# 🛠️ Assemble the PIL Document with enhanced structure\ndef generate_pil(petitioner, respondent, subject, summary):\n    \"\"\"Create the full PIL document with powerful Legal Grounds, Prayer, and Court Procedure generation.\"\"\"\n\n    print(\"⚡ Generating Legal Grounds...\")\n    legal_grounds_prompt = (\n        f\"Draft strong, persuasive legal grounds for a Public Interest Litigation (PIL) on '{subject}', \"\n        f\"citing specific constitutional articles, environmental laws (e.g., Environment Protection Act 1986), \"\n        f\"legal principles (e.g., Precautionary Principle, Polluter Pays Principle), and landmark cases (e.g., M.C. Mehta v. Union of India 1987).\"\n        f\"Ensure the argument is solid, legally backed, and supports the petitioner's cause.\"\n    )\n    legal_grounds = generate_gpt_section(legal_grounds_prompt, \"Legal Grounds\")\n\n    print(\"⚡ Generating Prayer...\")\n    prayer_prompt = (\n        f\"Draft a clear, practical, and enforceable prayer (request) for a PIL on '{subject}', \"\n        f\"including specific directives the court can issue (e.g., impose fines, enforce environmental audits, \"\n        f\"order cleanup operations, penalize non-compliant industries, ensure public data transparency).\"\n    )\n    prayer = generate_gpt_section(prayer_prompt, \"Prayer\")\n\n    print(\"⚡ Generating Court Procedure...\")\n    court_procedure_prompt = (\n        f\"Draft a legally accurate and step-by-step court procedure for filing a Public Interest Litigation (PIL) \"\n        f\"in the Supreme Court of India on '{subject}', ensuring it includes jurisdiction, notice, evidence submission, and requests for an expedited hearing.\"\n    )\n    court_procedure = generate_gpt_section(court_procedure_prompt, \"Court Procedure\")\n\n    # ✅ Fallback version of Court Procedure in case GPT fails\n    if \"⚠️\" in court_procedure:\n        court_procedure = (\n            \"1. File the PIL under Article 32 of the Constitution for Supreme Court jurisdiction.\\n\"\n            \"2. Serve notice to the Respondent and the Attorney General of India.\\n\"\n            \"3. Attach supporting evidence such as scientific data, expert affidavits, and media reports.\\n\"\n            \"4. Request expedited hearing citing urgent public interest.\"\n        )\n\n    # ✅ Assemble the final PIL document\n    pil_text = f\"\"\"\nIN THE HON'BLE SUPREME COURT OF INDIA\n\nPUBLIC INTEREST LITIGATION (PIL)\n\nPetitioner: {petitioner}\nRespondent: {respondent}\n\nSubject: {subject}\n\nRespected Lordships,\n\n{summary}\n\nLegal Grounds:\n{legal_grounds}\n\nPrayer:\n{prayer}\n\nCourt Procedure:\n{court_procedure}\n\nDate: {datetime.now().strftime(\"%A, %d %B %Y\")}\n\nYours sincerely,\n{petitioner}\n    \"\"\"\n\n    return pil_text\n\n\n# 📄 Export PIL to TXT and PDF\ndef export_pil(pil_text, filename=\"PIL_Document\"):\n    \"\"\"Export the PIL to text and PDF files.\"\"\"\n    # Save as TXT\n    with open(f\"{filename}.txt\", \"w\", encoding=\"utf-8\") as file:\n        file.write(pil_text)\n    print(f\"✅ PIL saved as {filename}.txt\")\n\n    # Save as PDF\n    pdf_file = f\"{filename}.pdf\"\n    c = canvas.Canvas(pdf_file, pagesize=A4)\n    c.setFont(\"Helvetica\", 12)\n    for i, line in enumerate(pil_text.split(\"\\n\")):\n        c.drawString(40, 800 - (i * 20), line)\n    c.save()\n    print(f\"✅ PIL saved as {pdf_file}\")\n\napp = Flask(__name__)\nCORS(app)  # Enable CORS for frontend communication\n\n@app.route('/run_pil_generator', methods=['POST'])\n    # 🎯 Interactive CLI for PIL Generation\ndef run_pil_generator():\n    data= request.json\n    subject = data.get('subject')\n    petitioner = data.get('petitioner')\n    respondent = data.get('respondent')\n    summary = data.get('summary')\n    \"\"\"Run the PIL Generator interactively.\"\"\"\n    print(\"🎉 Welcome to the PIL Generator!\")\n\n\n    # Generate the PIL document\n    print(\"⚡ Generating the complete PIL document...\")\n    generated_pil = generate_pil(petitioner, respondent, subject, summary)\n    return jsonify({'pil-text':generated_pil})\n# 🔥 Run the Generator\nif __name__ == \"__main__\":\n    app.run()\n","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"🚀 Loading GPT-2 model...\n"},{"name":"stderr","output_type":"stream","text":"Device set to use mps:0\n"},{"name":"stdout","output_type":"stream","text":" * Serving Flask app '__main__'\n * Debug mode: off\n"},{"name":"stderr","output_type":"stream","text":"WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n * Running on http://127.0.0.1:5000\nPress CTRL+C to quit\n127.0.0.1 - - [16/Mar/2025 17:49:13] \"OPTIONS /run_pil_generator HTTP/1.1\" 200 -\n"},{"name":"stdout","output_type":"stream","text":"🎉 Welcome to the PIL Generator!\n⚡ Generating the complete PIL document...\n⚡ Generating Legal Grounds...\n⚠️ Legal Grounds generation failed — retrying with stronger prompt...\n⚡ Generating Prayer...\n⚠️ Prayer generation failed — retrying with stronger prompt...\n⚡ Generating Court Procedure...\n⚠️ Court Procedure generation failed — retrying with stronger prompt...\n"},{"name":"stderr","output_type":"stream","text":"127.0.0.1 - - [16/Mar/2025 17:49:14] \"POST /run_pil_generator HTTP/1.1\" 200 -\n127.0.0.1 - - [16/Mar/2025 17:52:45] \"OPTIONS /run_pil_generator HTTP/1.1\" 200 -\n"},{"name":"stdout","output_type":"stream","text":"🎉 Welcome to the PIL Generator!\n⚡ Generating the complete PIL document...\n⚡ Generating Legal Grounds...\n⚠️ Legal Grounds generation failed — retrying with stronger prompt...\n"},{"name":"stderr","output_type":"stream","text":"127.0.0.1 - - [16/Mar/2025 17:52:46] \"POST /run_pil_generator HTTP/1.1\" 200 -\n"},{"name":"stdout","output_type":"stream","text":"⚡ Generating Prayer...\n⚠️ Prayer generation failed — retrying with stronger prompt...\n⚡ Generating Court Procedure...\n⚠️ Court Procedure generation failed — retrying with stronger prompt...\n"}],"execution_count":null},{"cell_type":"code","source":"pip install transformers[torch]","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"zsh:1: no matches found: transformers[torch]\nNote: you may need to restart the kernel to use updated packages.\n"}],"execution_count":2}]}